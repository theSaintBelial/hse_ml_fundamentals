{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "snxSUWXD7q_p",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1344b2929299b92f016973165a9acdbf",
     "grade": false,
     "grade_id": "cell-28fa66c6025a14a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Домашнее задание по неделе 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "j-8OLsAV7wrQ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb4c248e962e8c4365fdc7615a516585",
     "grade": false,
     "grade_id": "cell-209d95fed61d689d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Как было рассказано на лекции, стохастический градиентый спуск сходится быстрее, чем полный, хотя и менее стабильно. В этом задании вам предлагается реализовать стохастический градиентный спуск и сравнить его с точным вычислением весов линейной модели по скорости работы и значению метрики качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "IgQyWw5o7Nej",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20b1e5a3f34b071a37bbed5201cc774e",
     "grade": false,
     "grade_id": "cell-1fd6663bdd1d958d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "bGD1wQgMruJw",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b79179566bc57bcbdb1708206b9c69c1",
     "grade": false,
     "grade_id": "cell-21df819eb8028aa3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Задание 0\n",
    "\n",
    "Реализуйте класс ```LinearRegressionSGD``` c обучением и и применением линейной регрессии, построенной с помощью стохастического градиентного спуска, с заданным интерфейсом.\n",
    "\n",
    "Обратите внимание на следуюшие моменты:\n",
    "- Схожий класс использовался в семинаре. Ознакомление с ним упростит вам задачу.\n",
    "- Выбирайте **10** случайных сэмплов (равномерно) каждый раз. \n",
    "- Используйте параметры по умолчанию (epsilon=1e-6, max_steps=10000, w0=None, alpha=1e-8)\n",
    "- Выход из цикла осуществуется по сравнению 2-нормы разницы весов с epsilon, а функция потерь - MSE. (все, как в семинаре =)\n",
    "\n",
    "- При желании можете экспериментировать, попробовать выбирать 1<k<n случайных сэмплов и делиться результатами на форуме!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QZxdV27R9-uc"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class LinearRegressionSGD(BaseEstimator):\n",
    "    def __init__(self, epsilon=1e-6, max_steps=10000, w0=None, alpha=1e-8):\n",
    "        \"\"\"\n",
    "        epsilon: разница для нормы изменения весов \n",
    "        max_steps: максимальное количество шагов в градиентном спуске\n",
    "        w0: np.array (d,) - начальные веса\n",
    "        alpha: шаг обучения\n",
    "        \"\"\"\n",
    "        self.epsilon = epsilon\n",
    "        self.max_steps = max_steps\n",
    "        self.w0 = w0\n",
    "        self.alpha = alpha\n",
    "        self.w = None\n",
    "        self.w_history = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array (l, d)\n",
    "        y: np.array (l)\n",
    "        ---\n",
    "        output: self\n",
    "        \"\"\"\n",
    "        ## На каждом шаге градиентного спуска веса можно добавлять в w_history (для последующей отрисовки)\n",
    "        ## Для выполнения шага выберите 10 случайных(равномерно) сэмплов\n",
    "        \n",
    "        l, d = X.shape\n",
    "        \n",
    "        if self.w0 is None:\n",
    "            self.w0 = np.zeros(d)\n",
    "            \n",
    "        self.w = self.w0\n",
    "        \n",
    "        for step in range(self.max_steps):\n",
    "            self.w_history.append(self.w)\n",
    "            \n",
    "            w_new = self.w - self.alpha * self.calc_gradient(X, y)\n",
    "            \n",
    "            if (np.linalg.norm(w_new - self.w) < self.epsilon):\n",
    "                break\n",
    "                \n",
    "            self.w = w_new\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X: np.array (l, d)\n",
    "        ---\n",
    "        output: np.array (l)\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.w is None:\n",
    "            raise Exception(\"Not trained yet\")\n",
    "            \n",
    "        y_pred = np.dot(X, self.w)\n",
    "            \n",
    "        return y_pred\n",
    "    \n",
    "    def calc_gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array (l, d)\n",
    "        y: np.array (l)\n",
    "        ---\n",
    "        output: np.array (d)\n",
    "        \"\"\"\n",
    "\n",
    "        l, d = X.shape\n",
    "        \n",
    "        gradient = np.zeros((d, ))\n",
    "        indeces = np.random.randint(0, d, (10, ))\n",
    "        \n",
    "        for index in indeces:\n",
    "            gradient.append((2/l) * np.dot(X.T, (np.dot(X, self.w) - y))# np.dot(X[:, index].T, (np.dot(X[:, index], self.w[index]) - y[index])))\n",
    "            \n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "SNOm9-bXpdT3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6fbd786345377be954f67b7fd2f794f6",
     "grade": false,
     "grade_id": "cell-92905c42d017a52e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Проверять работу мы будем на имеющемся в sklearn наборе данных boston: в нём нужно по информации о доме предсказать его стоимость."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "c24JCwes9-pe"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_boston()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "9eIJwWnInXnr",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57a3cbcf5cfc9bca29bbbccf233cf84f",
     "grade": false,
     "grade_id": "cell-c13d71957341eb04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Задание 1\n",
    "\n",
    "Метрикой качества в нашей задаче будет MAPE - Mean Absolute Percentage Error. Реализуйте её с заданным интефейсом и вычислите \n",
    "```MAPE(y_test, y_0)```, где ```y_0 = (mean(y_test), mean(y_test), ...)```\n",
    "\n",
    "- Не забудьте умножить значение отношения на 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "znoDavxyuLsi"
   },
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred):\n",
    "    \"\"\"\n",
    "        y_true: np.array (l)\n",
    "        y_pred: np.array (l)\n",
    "        ---\n",
    "        output: float [0, +inf)\n",
    "    \"\"\"\n",
    "        \n",
    "    return np.sum(np.abs((y_true - y_pred) / y_true)) * (100 / len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "id": "e6mTAykeojwp",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c8e25d3ae3fda50058aeab4b1e9ccf0",
     "grade": false,
     "grade_id": "cell-85fd283621aa536b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.41588297684097"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_0 = [np.mean(y_test)] * y_test.shape[0]\n",
    "\n",
    "res_mape = MAPE(y_test, y_0)\n",
    "\n",
    "res_mape\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22f2e767db51c160d3e7546719cd6ae6",
     "grade": true,
     "grade_id": "cell-1a4a3674fae0ed39",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# проверка, просто запустите ячейку\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2nNy2ITxuMKf",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0706cdc94b830c6a920d78be86e660f2",
     "grade": false,
     "grade_id": "cell-33b1bb11aefb25ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Задание 2 \n",
    "\n",
    "Обучите ```LinearRegressionSGD``` с базовыми параметрами на тренировочном наборе данных (```X_train```, ```y_train```), сделайте предсказание на тестовых данных ```X_test```, записав результат в переменную ```y_pred_sgd```  и вычислите ошибку MAPE. Проверяться будет ошибка в переменной ```res_mape_SGD```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "id": "7BIHwAwUvB-N",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a81ff964b90011599bd6ac911a398023",
     "grade": false,
     "grade_id": "cell-5fff68c19d22725a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5b5c1d593668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegressionSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred_sgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mres_mape_SGD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_sgd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-623280685df5>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mw_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_new\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-623280685df5>\u001b[0m in \u001b[0;36mcalc_gradient\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindeces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mgradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# np.dot(X[:, index].T, (np.dot(X[:, index], self.w[index]) - y[index]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "sgd = LinearRegressionSGD().fit(X_train, y_train)\n",
    "\n",
    "y_pred_sgd = sgd.predict(X_test)\n",
    "\n",
    "res_mape_SGD = MAPE(y_test, y_pred_sgd)\n",
    "\n",
    "res_mape_SGD\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51214fba3a5cb1429be8055374aa8b88",
     "grade": true,
     "grade_id": "cell-1030801505081749",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# проверка, просто запустите ячейку\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "lWappMdMtIPV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0c2a71ef571ded4e56b010a933713c2",
     "grade": false,
     "grade_id": "cell-8f3341309c9cb5cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Задание 3\n",
    "\n",
    "Вычислите веса по точной формуле, используя ```X_train``` и ```y_train```; предскажите с их помощью целевую переменную на ```X_test```, записав результат в переменную ```y_pred_lr``` и вычислите ошибку MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "id": "wjMUlPje9-k0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8019327e693066205e3d2bc588893688",
     "grade": false,
     "grade_id": "cell-4196ac5307341014",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.953134816377787"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_true = np.dot(np.dot(np.linalg.inv(np.dot(X_train.T, X_train)), X_train.T), y_train)\n",
    "\n",
    "y_pred_lr = np.dot(X_test, w_true)\n",
    "\n",
    "res_mape_form = MAPE(y_test, y_pred_lr)\n",
    "\n",
    "res_mape_form\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f54235dee57065b3eb628f5a7b2fad0",
     "grade": true,
     "grade_id": "cell-4ad62f90912e454b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# проверка, просто запустите ячейку\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yL9L-4cwxZho",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "33e8d4fcd3383eb4fb1845eb426cce3b",
     "grade": false,
     "grade_id": "cell-f1a4c27cbb7aa329",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Бонусное задание по неделе 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "CZFaUn7yx04u",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f1bfad13499d6c0ccd3093a9edae710",
     "grade": false,
     "grade_id": "cell-93355af6e6c9dc1e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "До этого вы релизовывали модели, в которых не было штрафа за величину весов ```w```. Как было рассказано ранее в лекциях, это может привести к неустойчивости модели и переобучению. Чтобы избежать этих эффектов, предлагается добавить к оптимизируемому функционалу L2-норму весов; таким образом, будем решать задачу гребневой регрессии, Ridge:\n",
    "\n",
    "$$ \\frac{1}{l}(Xw-y)^T(Xw-y) +\\gamma||w||_2 \\rightarrow \\min_{w}. $$\n",
    "\n",
    "### Задание 11\n",
    "Реализуйте обучение такой модели в матричном виде (смотрите дополнительные материалы к этой неделе) с помощью стохастического градиентного спуска. Класс должен совпадать по набору реализованных функций с ```LinearRegressionVectorized```, разница будет лишь в параметре $\\gamma$, отвечающем за степень регуляризации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TEXqBqmGxWDz"
   },
   "outputs": [],
   "source": [
    "class RidgeSGD(BaseEstimator):\n",
    "    def __init__(self, epsilon=1e-6, max_steps=10000, w0=None, alpha=1e-8, gamma=0):\n",
    "        \"\"\"\n",
    "        epsilon: разница для нормы изменения весов \n",
    "        max_steps: максимальное количество шагов в градиентном спуске\n",
    "        w0: np.array (d,) - начальные веса\n",
    "        alpha: шаг обучения\n",
    "        gamma: коэффициент регуляризации\n",
    "        \"\"\"\n",
    "        self.epsilon = epsilon\n",
    "        self.max_steps = max_steps\n",
    "        self.w0 = w0\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.w = None\n",
    "        self.w_history = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array (l, d)\n",
    "        y: np.array (l)\n",
    "        ---\n",
    "        output: self\n",
    "        \"\"\"\n",
    "        ## На каждом шаге градиентного спуска веса можно добавлять в w_history (для последующей отрисовки)\n",
    "        ## Для выполнения шага выберите 10 случайных(равномерно) сэмплов\n",
    "        \n",
    "        l, d = X.shape\n",
    "        \n",
    "        if self.w0 is None:\n",
    "            self.w0 = np.zeros(d)\n",
    "            \n",
    "        self.w = self.w0\n",
    "        \n",
    "        for step in range(self.max_steps):\n",
    "            self.w_history.append(self.w)\n",
    "            \n",
    "            w_new = self.w - self.alpha * self.calc_gradient(X, y)\n",
    "            \n",
    "            if (np.linalg.norm(w_new - self.w) < self.epsilon):\n",
    "                break\n",
    "                \n",
    "            self.w = w_new\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X: np.array (l, d)\n",
    "        ---\n",
    "        output: np.array (l)\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.w is None:\n",
    "            raise Exception(\"Not trained yet\")\n",
    "            \n",
    "        y_pred = np.dot(X, self.w)\n",
    "            \n",
    "        return y_pred\n",
    "    \n",
    "    def calc_gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array (l, d)\n",
    "        y: np.array (l)\n",
    "        ---\n",
    "        output: np.array (d)\n",
    "        \"\"\"\n",
    "\n",
    "        l, d = X.shape\n",
    "        \n",
    "        gradient = np.zeros((d, ))\n",
    "        indeces = np.random.randint(0, d, (10, ))\n",
    "        \n",
    "        for index in indeces:\n",
    "            gradient[index] = (2/l) * np.dot(X[:, index].T, (np.dot(X[:, index], self.w[index]) - y[index])) + 2 * self.gamma * self.w[index]\n",
    "            \n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6t9rqXFu8Pq6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c9a2d324fd4e2b1116c18b4b79ba6df",
     "grade": false,
     "grade_id": "cell-203b5187aeb47f99",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Так же, как и в основном задании, обучите модель с базовыми параметрами на тренировочных данных и сделайте прогноз y_pred_ridge. Выведите значение MAPE(y_test, y_pred_ridge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6A2hak_A8QPO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.10631287593901"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = RidgeSGD(gamma=5).fit(X_train, y_train)\n",
    "\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "res_mape_ridge = MAPE(y_test, y_pred_ridge)\n",
    "\n",
    "res_mape_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW04_sgd.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
